{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "from utils import load_features_and_labels\n",
    "from models.gaussian_process import train_gp_model\n",
    "\n",
    "import rdkit.Chem as Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles, X, X_p, y = load_features_and_labels('./processed_data/initial_dataset/jtnn_features.csv' ,'./raw_data/photoswitches_2.csv' ,'e_iso_pi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beginning training loop...\n",
      "\n",
      "mean R^2: 0.8601 +- 0.0144\n",
      "mean RMSE: 23.8784 +- 1.4816\n",
      "mean MAE: 14.8252 +- 0.6878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, x_scaler, y_scaler = train_gp_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./FastJTNNpy3/')\n",
    "\n",
    "# starting smiles\n",
    "smiles = \"Cn1c(C#N)ccc1-c1ccc(N=Nc2ccc(-c3ccc(C#N)n3C)s2)s1\"\n",
    "\n",
    "from FastJTNNpy3.fast_molvae.sample import load_model\n",
    "vae_model = load_model('./FastJTNNpy3/data/vocab.txt', './FastJTNNpy3/fast_molvae/vae_model/model.epoch-19')\n",
    "\n",
    "features = vae_model.encode_from_smiles([smiles])\n",
    "\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "fp1 = AllChem.GetMorganFingerprint(mol, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[444.09740468]]\n"
     ]
    }
   ],
   "source": [
    "features = features.detach().numpy().astype('float')\n",
    "\n",
    "output = model.predict_f(features)\n",
    "print(y_scaler.inverse_transform(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wavelength(smiles):\n",
    "  features = vae_model.encode_from_smiles([smiles])\n",
    "  features = features.detach().numpy().astype('float')\n",
    "  output = model.predict_f(features)\n",
    "  wavelength = y_scaler.inverse_transform(output[0])[0][0]\n",
    "  return wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_latent(tree_vec, mol_vec):\n",
    "  tree_vec = torch.from_numpy(tree_vec.numpy()).float()\n",
    "  mol_vec = torch.from_numpy(mol_vec.numpy()).float()\n",
    "  tree_mean = vae_model.T_mean(tree_vec)\n",
    "  mol_mean = vae_model.G_mean(mol_vec)\n",
    "  smiles = vae_model.decode(tree_mean, mol_mean, prob_decode=False)\n",
    "  return smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N#Cc1cnc(N2CCN(Cc3c[nH]c(N)c3C#N)CC2)nc1Nc1cccnc1\n",
      "441.3155853110432\n"
     ]
    }
   ],
   "source": [
    "n_iter = 50\n",
    "lr = 5.0\n",
    "sim_cutoff = 0.4\n",
    "\n",
    "curr_vec = features\n",
    "visited = []\n",
    "\n",
    "for step in range(n_iter):\n",
    "  curr_vec_tf = tf.Variable(curr_vec, name='curr_vec')\n",
    "  with tf.GradientTape() as tape:\n",
    "    wavelength, _ = model.predict_f(curr_vec_tf)\n",
    "  grad = tape.gradient(wavelength, curr_vec_tf)\n",
    "  curr_vec = curr_vec + lr * grad\n",
    "  visited.append(curr_vec)\n",
    "  \n",
    "  # tree_vec, mol_vec = tf.split(curr_vec, num_or_size_splits=2, axis=1)\n",
    "  # new_smiles = decode_latent(tree_vec, mol_vec)\n",
    "  # print(new_smiles)\n",
    "  # print(predict_wavelength(new_smiles))  \n",
    "  \n",
    "l, r = 0, n_iter - 1\n",
    "while l < r - 1:\n",
    "  mid = int((l + r) / 2)\n",
    "  new_vec = visited[mid]\n",
    "  tree_vec, mol_vec = tf.split(new_vec, num_or_size_splits=2, axis=1)\n",
    "  new_smiles = decode_latent(tree_vec, mol_vec)\n",
    "  if new_smiles is None:\n",
    "    r = mid - 1\n",
    "    continue\n",
    "\n",
    "  new_mol = Chem.MolFromSmiles(new_smiles)\n",
    "  fp2 = AllChem.GetMorganFingerprint(new_mol, 2)\n",
    "  sim = DataStructs.TanimotoSimilarity(fp1, fp2) \n",
    "  if sim < sim_cutoff:\n",
    "      r = mid - 1\n",
    "  else:\n",
    "      l = mid\n",
    "\n",
    "tree_vec, mol_vec = tf.split(visited[l], num_or_size_splits=2, axis=1)\n",
    "new_smiles = decode_latent(tree_vec, mol_vec)\n",
    "print(new_smiles)\n",
    "print(predict_wavelength(new_smiles))  \n",
    "new_mol = Chem.MolFromSmiles(new_smiles)\n",
    "fp2 = AllChem.GetMorganFingerprint(new_mol, 2)\n",
    "sim = DataStructs.TanimotoSimilarity(fp1, fp2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d019af4eb531d940badc250160803862d398cacfe03997acb3b0d3467f546b9c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
